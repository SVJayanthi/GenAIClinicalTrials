{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c81da886",
   "metadata": {},
   "source": [
    "# Pandas Dataframe Agent\n",
    "\n",
    "This notebook shows how to use agents to interact with a pandas dataframe. It is mostly optimized for question answering.\n",
    "\n",
    "**NOTE: this agent calls the Python agent under the hood, which executes LLM generated Python code - this can be bad if the LLM generated Python code is harmful. Use cautiously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784e9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filepath = 'credentials.json'\n",
    "file = open(filepath, 'r')\n",
    "\n",
    "# Open the credentials file with json.load\n",
    "credentials = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c5841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (0.0.170)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: tabulate in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: asyncio in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: pyee in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (9.0.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pyee) (4.5.0)\n",
      "Requirement already satisfied: playwright in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: greenlet==2.0.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from playwright) (2.0.1)\n",
      "Requirement already satisfied: pyee==9.0.4 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from playwright) (9.0.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from pyee==9.0.4->playwright) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install openai\n",
    "!pip install tabulate\n",
    "!pip install asyncio\n",
    "!pip install pyee\n",
    "!pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fa177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper.fda_generated_scraper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3648aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "INFO: selector not valid - probably the parent object is the object\n",
      "[{'drugName': 'Abcema (idecabtagene vicleucel)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel'}, {'drugName': 'Abilify (aripiprazole)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3060-abilify-aripiprazole'}, {'drugName': 'Abraxane (paclitaxel protein-bound particles for injectable suspension)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3061-abraxane-paclitaxel-protein-bound-particles-for-injectable-suspension'}, {'drugName': 'Abstral (fentanyl sublingual tablets)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3063-abstral-fentanyl-sublingual-tablets'}, {'drugName': 'Abthrax (raxibacumab)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3064-abthrax-raxibacumab'}, {'drugName': 'Accolate (zafirlukast)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3066-accolate-zafirlukast'}, {'drugName': 'Aciphex (rabeprazole sodium)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3068-aciphex-rabeprazole-sodium'}, {'drugName': 'Actemra (tocilizumab)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4692-actemra-tocilizumab'}, {'drugName': 'Activella (Estradiol/Norethindrone Acetate) Tablets', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3074-activella-estradiol-norethindrone-acetate-tablets'}, {'drugName': 'Actonel', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3075-actonel'}, {'drugName': 'Actos (pioglitazone); ACTOplus met (pioglitazone and metformin HCl)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3077-actos-pioglitazone-actoplus-met-pioglitazone-and-metformin-hcl'}, {'drugName': 'Acular (ketorolac tromethamine) ophthalmic solution', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3079-acular-ketorolac-tromethamine-ophthalmic-solution'}, {'drugName': 'Acuvail (ketorolac tromethamine)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3080-acuvail-ketorolac-tromethamine'}, {'drugName': 'Adakveo (crizanlizumab-tmca)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4558-adakveo-crizanlizumab-tmca'}, {'drugName': 'Adbry (tralokinumab-ldrm)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4767-adbry-tralokinumab-ldrm'}, {'drugName': 'Adcetris (brentuximab vedotin)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3082-adcetris-brentuximab-vedotin'}, {'drugName': 'Adcirca (tadalafil)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3083-adcirca-tadalafil'}, {'drugName': 'Adderall (mixed salts of a single-entity amphetamine)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3084-adderall-mixed-salts-of-a-single-entity-amphetamine'}, {'drugName': 'Adderall XR', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3085-adderall-xr'}, {'drugName': 'Addyi (flibanserin)', 'link': 'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/3086-addyi-flibanserin'}]\n"
     ]
    }
   ],
   "source": [
    "data = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad133264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
    "from langchain.docstore.document import Document\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "# Needed synce jupyter runs an async eventloop\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95757e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "from langchain.agents import tool, Tool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "\n",
    "ROOT_DIR = \"./data/\"\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    os.makedirs(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0503d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def pushd(new_dir):\n",
    "    \"\"\"Context manager for changing the current working directory.\"\"\"\n",
    "    prev_dir = os.getcwd()\n",
    "    os.chdir(new_dir)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(prev_dir)\n",
    "\n",
    "@tool\n",
    "def process_csv(\n",
    "    csv_file_path: str, instructions: str, output_path: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Process a CSV by with pandas in a limited REPL.\\\n",
    " Only use this after writing data to disk as a csv file.\\\n",
    " Any figures must be saved to disk to be viewed by the human.\\\n",
    " Instructions should be written in natural language, not code. Assume the dataframe is already loaded.\"\"\"\n",
    "    with pushd(ROOT_DIR):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "        agent = create_pandas_dataframe_agent(llm, df, max_iterations=30, verbose=True)\n",
    "        if output_path is not None:\n",
    "            instructions += f\" Save output to disk at {output_path}\"\n",
    "        try:\n",
    "            result = agent.run(instructions)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb0cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b01a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab767458",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_load_webpage(url: str) -> str:\n",
    "    \"\"\"Load the specified URLs using Playwright and parse using BeautifulSoup.\"\"\"\n",
    "    browser = await launch(\n",
    "        headless=True,\n",
    "        timeout=100000,\n",
    "        ignoreDefaultArgs=[\"--enable-automation\"],\n",
    "        args=[],\n",
    "        defaultViewport=None\n",
    "    )\n",
    "\n",
    "    page = await browser.newPage()\n",
    "\n",
    "    await page.goto(url, waitUntil=[\"networkidle2\"], timeout=15000)\n",
    "    \n",
    "    # Get the HTML content of the page\n",
    "    content = await page.content()\n",
    "\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    results = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    await browser.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e500e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com'\n",
    "page = await async_load_webpage(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf635ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, DuckDuckGoSearchRun\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pydantic import Field\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain, BaseCombineDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_text_splitter():\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap  = 20,\n",
    "        length_function = len,\n",
    "    )\n",
    "\n",
    "\n",
    "class WebpageQATool(BaseTool):\n",
    "    name = \"query_webpage\"\n",
    "    description = \"Browse a webpage and retrieve the information relevant to the question.\"\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
    "    qa_chain: BaseCombineDocumentsChain\n",
    "    \n",
    "    def _run(self, url: str, question: str) -> str:\n",
    "        \"\"\"Useful for browsing websites and scraping the text information.\"\"\"\n",
    "        result = asyncio.get_event_loop().run_until_complete(async_load_webpage(url))\n",
    "        # print(type(result))\n",
    "        docs = [Document(page_content=result, metadata={\"source\": url})]\n",
    "        web_docs = self.text_splitter.split_documents(docs)\n",
    "        results = []\n",
    "        # TODO: Handle this with a MapReduceChain\n",
    "        for i in range(0, len(web_docs), 4):\n",
    "            input_docs = web_docs[i:i+4]\n",
    "            window_result = self.qa_chain({\"input_documents\": input_docs, \"question\": question}, return_only_outputs=True)\n",
    "            results.append(f\"Response from window {i} - {window_result}\")\n",
    "        results_docs = [Document(page_content=\"\\n\".join(results), metadata={\"source\": url})]\n",
    "        return self.qa_chain({\"input_documents\": results_docs, \"question\": question}, return_only_outputs=True)\n",
    "    \n",
    "    async def _arun(self, url: str, question: str) -> str:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a067b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac175136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=credentials[\"OPENAI_API_KEY\"])\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175ca49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckduckgo_search\n",
    "# web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=credentials[\"SERPAPI_API_KEY\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5cc14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['drugName', 'link'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248450f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClinicalData = data\n",
    "drug_names = [d['drugName'] for d in ClinicalData]\n",
    "drug_tuples = [(d['drugName'], embeddings_model.embed_query(d['drugName'])) for d in ClinicalData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c367acf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9d0b470c-9776-4145-88d5-f6913fc9eae4',\n",
       " '04154076-23df-43d0-b069-31a5ee22fef1',\n",
       " '453cb1df-117e-456c-9221-f2918f57fe64',\n",
       " 'f3936892-e33b-4b53-8619-133d1010a94e',\n",
       " '50106ec1-4f9c-4f5d-9acd-fe0ffcde0e8f',\n",
       " '4e683537-f674-4a1d-b206-c977157a2143',\n",
       " '1ae76cdc-7836-48ed-9525-d28c9254ea4b',\n",
       " '6b92bb34-1bba-4f26-8d63-f1d94ac64287',\n",
       " '3e4544bd-0612-45f8-8468-29655418a441',\n",
       " 'b08ae60c-80c2-45fb-bda3-9b1546692c25',\n",
       " 'bfde4944-019a-46e0-8b8c-1e92e4a93e23',\n",
       " 'f9f5d5d6-4d37-4ef7-ae33-0315cf1143fb',\n",
       " 'afff2bc2-a8f9-4df5-9acb-8714a4e75441',\n",
       " '131b8bb7-a10e-4988-8a95-a23ed18e0c1a',\n",
       " 'db719640-3c03-47a4-8df2-a52fa587c476',\n",
       " 'e08fa2f6-ba4e-4daa-9fb9-bac4c33082ac',\n",
       " '450b492c-3b3c-4b61-ad73-a5c8b13088ca',\n",
       " '31a6ef96-c18f-41a7-befe-6038b9845c27',\n",
       " '108aa089-d26e-4045-9844-00a9c581801e',\n",
       " 'fdbd8193-ea4f-4d1c-9952-060c6d89bb7e']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "drug_store = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
    "drug_store.add_embeddings(drug_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f7b4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_drug = drug_store.similarity_search(\"Abcema\", k=1)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe9c49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_link = ClinicalData[drug_names.index(closest_drug)][\"link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bc5395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e05cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClinicalLinkTool(BaseTool):\n",
    "    name = \"get_link_for_clinical_trial\"\n",
    "    description = \"useful for getting  the link of the clinical trial data for a specific drug\"\n",
    "    drug_name: str = Field(default=\"\", description=\"the drug name\")\n",
    "\n",
    "    def _run(self, drug_name: str) -> str:\n",
    "        # query = embeddings_model.embed_query(drug_name)\n",
    "        closest_drug = drug_store.similarity_search(drug_name, k=1)[0].page_content\n",
    "        closest_link = ClinicalData[drug_names.index(closest_drug)][\"link\"]\n",
    "        return f\"The closest drug found was {closest_drug} whose corresponding link is {closest_link}\"\n",
    "    \n",
    "    async def _arun(self, url: str, question: str) -> str:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f635605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=1.0, openai_api_key=credentials[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8047b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_website_tool = WebpageQATool(qa_chain=load_qa_with_sources_chain(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36499744",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "Navigation Timeout Exceeded: 15000 ms exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m query_website_tool\u001b[39m.\u001b[39;49m_run(\u001b[39m'\u001b[39;49m\u001b[39mhttps://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mWhat are the clinical trial results?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m, in \u001b[0;36mWebpageQATool._run\u001b[1;34m(self, url, question)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m, question: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     17\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Useful for browsing websites and scraping the text information.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     result \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mget_event_loop()\u001b[39m.\u001b[39;49mrun_until_complete(async_load_webpage(url))\n\u001b[0;32m     19\u001b[0m     \u001b[39m# print(type(result))\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     docs \u001b[39m=\u001b[39m [Document(page_content\u001b[39m=\u001b[39mresult, metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: url})]\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[0;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mEvent loop stopped before Future completed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\asyncio\\tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36masync_load_webpage\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      3\u001b[0m browser \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m launch(\n\u001b[0;32m      4\u001b[0m     headless\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     timeout\u001b[39m=\u001b[39m\u001b[39m100000\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     defaultViewport\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m page \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m browser\u001b[39m.\u001b[39mnewPage()\n\u001b[1;32m---> 13\u001b[0m \u001b[39mawait\u001b[39;00m page\u001b[39m.\u001b[39mgoto(url, waitUntil\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mnetworkidle2\u001b[39m\u001b[39m\"\u001b[39m], timeout\u001b[39m=\u001b[39m\u001b[39m15000\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Get the HTML content of the page\u001b[39;00m\n\u001b[0;32m     16\u001b[0m content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m page\u001b[39m.\u001b[39mcontent()\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\pyppeteer\\page.py:837\u001b[0m, in \u001b[0;36mPage.goto\u001b[1;34m(self, url, options, **kwargs)\u001b[0m\n\u001b[0;32m    835\u001b[0m error \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mexception()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[1;32m--> 837\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m    839\u001b[0m request \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(mainFrame\u001b[39m.\u001b[39m_navigationURL)\n\u001b[0;32m    840\u001b[0m \u001b[39mreturn\u001b[39;00m request\u001b[39m.\u001b[39mresponse \u001b[39mif\u001b[39;00m request \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: Navigation Timeout Exceeded: 15000 ms exceeded."
     ]
    }
   ],
   "source": [
    "query_website_tool._run('https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel', \"What are the clinical trial results?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9954ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The closest drug found was Abcema (idecabtagene vicleucel) whose corresponding link is https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClinicalLinkTool()._run(\"Abecema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fce7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # Tool(\n",
    "    #     name = \"search\",\n",
    "    #     func=search.run,\n",
    "    #     description=\"General internet search for high level information \"\n",
    "    # ),\n",
    "    ClinicalLinkTool(),\n",
    "    WriteFileTool(root_dir=\"./data\"),\n",
    "    ReadFileTool(root_dir=\"./data\"),\n",
    "    process_csv,\n",
    "    query_website_tool,\n",
    "    HumanInputRun(), # Activate if you want the permit asking for help from the human\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc7390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srava\\anaconda3\\envs\\autogpt\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00cba912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Subbarao\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "    # human_in_the_loop=True, # Set to True if you want to add feedback at each step.\n",
    ")\n",
    "agent.chain.set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24eefeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I need to find information on the clinical trial results of a drug called Abcema. I should use the get_link_for_clinical_trial command to get the link to the clinical trial data for Abcema, and then use the query_webpage command to get the relevant data from the webpage. Finally, I should use the write_file command to write the data to a text file.\",\n",
      "        \"reasoning\": \"This approach will allow me to efficiently locate the relevant data and store it for future reference.\",\n",
      "        \"plan\": \"- Use get_link_for_clinical_trial to get the link to the clinical trial data for Abcema\\n- Use query_webpage to get the relevant data from the webpage\\n- Use write_file to write the data to a text file\",\n",
      "        \"criticism\": \"\",\n",
      "        \"speak\": \"I will use the get_link_for_clinical_trial, query_webpage, and write_file commands to get the clinical trial results for Abcema.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"get_link_for_clinical_trial\",\n",
      "        \"args\": {\n",
      "            \"drug_name\": \"Abcema\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"Now I have the link to the clinical trial data for Abcema, I should use the query_webpage command to get the relevant results from the webpage. I will pass the link to query_webpage.\",\n",
      "        \"reasoning\": \"Using query_webpage will allow me to retrieve the clinical trial results for Abcema from the webpage.\",\n",
      "        \"plan\": \"- Use query_webpage to get the relevant data from the webpage\",\n",
      "        \"criticism\": \"\",\n",
      "        \"speak\": \"I will use the query_webpage command to extract the clinical trial results for Abcema from the linked webpage.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"query_webpage\",\n",
      "        \"args\": {\n",
      "            \"url\": \"https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel\",\n",
      "            \"question\": \"What are the clinical trial results for Abcema?\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"Now that I have the relevant clinical trial results for Abcema, I should use the write_file command to write the data to a text file.\",\n",
      "        \"reasoning\": \"This will allow me to store the data in a more readable format and allow for future reference.\",\n",
      "        \"plan\": \"- Use write_file to write the extracted data to a text file\",\n",
      "        \"criticism\": \"\",\n",
      "        \"speak\": \"I will use the write_file command to write the clinical trial results for Abcema to a text file.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"write_file\",\n",
      "        \"args\": {\n",
      "            \"file_path\": \"abcema_clinical_trial_results.txt\",\n",
      "            \"text\": \"Abcema Clinical Trial Results:\\n- Overall response rate: 94%\\n- Complete response rate: 40%\\n- Duration of response: 10.6 months\\n- Progression-free survival: 8.6 months\\n- Adverse effects: cytokine release syndrome, infections, fatigue, musculoskeletal pain, and hypogammaglobulinemia.\\n- Further information on adverse effects can be found on the drug label, which has a black box warning and a Risk Evaluation and Mitigation Strategy (REMS).\\nSOURCE: https://www.centerwatch.com/directories/1067-fda-approved-drugs/listing/4697-abcema-idecabtagene-vicleucel\",\n",
      "            \"append\": false\n",
      "        }\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"There are currently no further tasks to complete, as I have successfully obtained the clinical trial results for Abcema, extracted the relevant information from the webpage, and stored it in a text file. I will use the finish command to signal that I have finished all my objectives.\",\n",
      "        \"reasoning\": \"All tasks have been successfully completed.\",\n",
      "        \"plan\": \"\",\n",
      "        \"criticism\": \"\",\n",
      "        \"speak\": \"I have successfully completed all my objectives. I will use the finish command to signal that I have completed my tasks.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"finish\",\n",
      "        \"args\": {\n",
      "            \"response\": \"All objectives have been successfully completed.\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All objectives have been successfully completed.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run([\"What is the clinical trial results of the drug Abcema? Use the link from the clinical trials tool, query the webpage, and write the response to a text file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb95da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run([\"What is the latest data about the top pharamaceutical companies with the most recent clinically approved drugs on the market.  Use the link from the clinical trials tool, query the webpage, and write the response to a text file.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e833d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoGPT' object has no attribute 'llm_chain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(agent\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mmessages[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mtemplate)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoGPT' object has no attribute 'llm_chain'"
     ]
    }
   ],
   "source": [
    "print(agent.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Unfortunately, Assistant is terrible at maths. When provided with math questions, no matter how simple, assistant always refers to it's trusty tools and absolutely does NOT try to answer math questions by itself\n",
    "\n",
    "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc26b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = agent.agent.create_prompt(\n",
    "    system_message=sys_msg,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "agent.agent.llm_chain.prompt = new_prompt\n",
    "agent.tools = tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f475637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.parsehub.com/api/v2/projects/accessdata.fda.gov/run\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {credentials['ParseHub_API_KEY']}\",\n",
    "}\n",
    "data = {\n",
    "    \"start_url\": \"https://www.example.com\",\n",
    "    \"api_key\": 'API_KEY',\n",
    "    \"output_format\": \"json\"\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "if response.status_code == 200:\n",
    "    run_token = response.json()[\"run_token\"]\n",
    "    # retrieve the data from the Parsehub API using the run token\n",
    "else:\n",
    "    print(\"Error:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20156f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "project_token = 'tkkE7ZdThusq'\n",
    "api_key = credentials[\"ParseHub_API_KEY\"]\n",
    "url = f'https://www.parsehub.com/api/v2/projects/{project_token}/run'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "}\n",
    "data = {\n",
    "    'start_url': 'https://www.example.com',\n",
    "    'start_template': 'main_template',\n",
    "    'start_value_override': '{\"query\": \"python\"}',\n",
    "    'start_url_params': {'lang': 'en'},\n",
    "    'send_email': False,\n",
    "    'email': '',\n",
    "    'webhook': '',\n",
    "    'output_format': 'csv',\n",
    "    'store_data': True,\n",
    "    'csv_filename': 'output.csv',\n",
    "    'json_filename': '',\n",
    "    'xml_filename': '',\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "if response.status_code == 200:\n",
    "    run_token = response.json()['run_token']\n",
    "    print(f'Run started successfully. Run token: {run_token}')\n",
    "else:\n",
    "    print(f'Error starting run. Status code: {response.status_code}, message: {response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e152e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"api_key\": api_key,\n",
    "  \"format\": \"json\"\n",
    "}\n",
    "run_token = \"tH0n_Abvu-R8\"\n",
    "r = requests.get(f'https://www.parsehub.com/api/v2/runs/{run_token}/data', params=params)\n",
    "fda_data = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9abdcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from langchain.agents import (\n",
    "    create_json_agent,\n",
    "    AgentExecutor\n",
    ")\n",
    "from langchain.agents.agent_toolkits import JsonToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.tools.json.tool import JsonSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7464d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_spec = JsonSpec(dict_=fda_data, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=llm,\n",
    "    toolkit=json_toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_agent_executor.run(\"What is the earliest data of the first drug to be approved and from what company is it from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "31e85aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"api_key\": credentials['ParseHub_API_KEY'],\n",
    "    \"format\": \"csv\"\n",
    "}\n",
    "run_token = \"txQULvz0mXRa\"\n",
    "r = requests.get(f'https://www.parsehub.com/api/v2/runs/{run_token}/data', params=params)\n",
    "fda_data = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b7b4fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, DuckDuckGoSearchRun\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pydantic import Field\n",
    "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "# from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain, BaseCombineDocumentsChain\n",
    "def _get_text_splitter():\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap  = 20,\n",
    "        length_function = len,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "135dd565",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StuffDocumentsChain' object has no attribute 'chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m doc2 \u001b[39m=\u001b[39m Document(page_content\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis is document 2.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Combine documents\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m combined_documents \u001b[39m=\u001b[39m stuff_documents_chain\u001b[39m.\u001b[39;49mchains([doc1, doc2])\n\u001b[0;32m     24\u001b[0m \u001b[39m# Generate result using the combined_documents as context\u001b[39;00m\n\u001b[0;32m     25\u001b[0m result \u001b[39m=\u001b[39m llm_chain\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m     26\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhat do you know about the documents?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     context\u001b[39m=\u001b[39mcombined_documents\u001b[39m.\u001b[39mpage_content\n\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StuffDocumentsChain' object has no attribute 'chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "\n",
    "template = \"\"\"{context} What do you know about the documents?\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\"])\n",
    "# Prepare LLMChain instance\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Create StuffDocumentsChain instance\n",
    "stuff_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"context\",\n",
    "    document_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Prepare documents\n",
    "doc1 = Document(page_content=\"This is document 1.\")\n",
    "doc2 = Document(page_content=\"This is document 2.\")\n",
    "\n",
    "# Combine documents\n",
    "combined_documents = stuff_documents_chain.chains([doc1, doc2])\n",
    "\n",
    "# Generate result using the combined_documents as context\n",
    "result = llm_chain.generate(\n",
    "    prompt=\"What do you know about the documents?\",\n",
    "    context=combined_documents.page_content\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts[:3]]\n",
    "chain = load_summarize_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_intermediate_steps=True)\n",
    "chain.run(docs)\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONCISE SUMMARY IN ITALIAN:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_intermediate_steps=True, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9d80b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = Document(page_content=\"This is document 1.\")\n",
    "doc2 = Document(page_content=\"This is document 2.\")\n",
    "docs = [doc1, doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "23a4863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fda_data = (r.text)\n",
    "docs = [Document(page_content=fda_data)]\n",
    "# web_docs = RecursiveCharacterTextSplitter().split_text(fda_data)\n",
    "web_docs = RecursiveCharacterTextSplitter().split_documents(docs)\n",
    "len(web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bb8ddc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4773f1cff2f475b82c1652a8045f09a6 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 32ff9f8b4e39741969cc4bc8f870f1bf in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0cf7a9694b162e77188c9f71048c9e65 in your message.).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(llm, \n\u001b[0;32m     19\u001b[0m                              chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmap_reduce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m                             \u001b[39m#  prompt = BULLET_POINT_PROMPT)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m output_summary \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(web_docs)\n\u001b[0;32m     23\u001b[0m wrapped_text \u001b[39m=\u001b[39m textwrap\u001b[39m.\u001b[39mfill(output_summary, \n\u001b[0;32m     24\u001b[0m                              width\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m     25\u001b[0m                              break_long_words\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     26\u001b[0m                              replace_whitespace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(wrapped_text)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[1;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[0;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[0;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:144\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[0;32m    133\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    134\u001b[0m     docs: List[Document],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    138\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[0;32m    139\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \n\u001b[0;32m    141\u001b[0m \u001b[39m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    145\u001b[0m         \u001b[39m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[0;32m    146\u001b[0m         [{\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_variable_name: d\u001b[39m.\u001b[39;49mpage_content, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs} \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m docs],\n\u001b[0;32m    147\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_results(\n\u001b[0;32m    150\u001b[0m         results, docs, token_max, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    151\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\llm.py:157\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    156\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    158\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n\u001b[0;32m    159\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end({\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: outputs})\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\llm.py:154\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    151\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput_list\u001b[39m\u001b[39m\"\u001b[39m: input_list},\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    155\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    156\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chains\\llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\base.py:143\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    138\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m    139\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    142\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\base.py:91\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     92\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[0;32m     93\u001b[0m generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\base.py:83\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[0;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m     84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     85\u001b[0m         \u001b[39mif\u001b[39;49;00m new_arg_supported\n\u001b[0;32m     86\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m     87\u001b[0m         \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m messages\n\u001b[0;32m     88\u001b[0m     ]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\base.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m---> 84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m     86\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[0;32m     88\u001b[0m     ]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\openai.py:296\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager)\u001b[0m\n\u001b[0;32m    292\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[0;32m    293\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[0;32m    294\u001b[0m     )\n\u001b[0;32m    295\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[1;32m--> 296\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\openai.py:257\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\langchain\\chat_models\\openai.py:255\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[0;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[0;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    517\u001b[0m         method,\n\u001b[0;32m    518\u001b[0m         abs_url,\n\u001b[0;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[0;32m    525\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\srava\\anaconda3\\envs\\autogpt\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "question = \"How many drugs are there in this dataset?\"\n",
    "prompt_template = \"\"\"Using the below dataset\n",
    "{text}\n",
    "\n",
    "Answer this \"\"\" + question + \":\"\n",
    "\n",
    "fda_data = (r.text)\n",
    "docs = [Document(page_content=fda_data)]\n",
    "# web_docs = RecursiveCharacterTextSplitter().split_text(fda_data)\n",
    "web_docs = RecursiveCharacterTextSplitter().split_documents(docs)\n",
    "\n",
    "\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template,\n",
    "                        input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"map_reduce\")\n",
    "                            #  prompt = BULLET_POINT_PROMPT)\n",
    "\n",
    "output_summary = chain.run(web_docs)\n",
    "wrapped_text = textwrap.fill(output_summary, \n",
    "                             width=100,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDADatabaseTool(BaseTool):\n",
    "    name = \"table_for_searching_through_fda_database\"\n",
    "    description = \"useful for getting the data about FDA approved drugs\"\n",
    "    question: str = Field(default=\"\", description=\"the question you want to ask of the database\")\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
    "\n",
    "    def _run(self, question: str) -> str:\n",
    "        \"\"\"Useful for browsing websites and scraping the text information.\"\"\"\n",
    "        prompt_template = \"\"\"Using the below dataset\n",
    "        {text}\n",
    "\n",
    "        Answer this \"\"\" + question + \":\"\n",
    "\n",
    "        BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template,\n",
    "                                input_variables=[\"text\"])\n",
    "\n",
    "        chain = load_summarize_chain(llm, \n",
    "                                    chain_type=\"stuff\",\n",
    "                                    prompt = BULLET_POINT_PROMPT)\n",
    "        web_docs = self.text_splitter.split_documents(docs)\n",
    "\n",
    "        output_summary = chain.run(web_docs)\n",
    "        wrapped_text = textwrap.fill(output_summary, \n",
    "                                    width=100,\n",
    "                                    break_long_words=False,\n",
    "                                    replace_whitespace=False)\n",
    "        \n",
    "        return wrapped_text\n",
    "    \n",
    "    async def _arun(self, question: str) -> str:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b481e366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no relevant information in the given dataset to answer this question.'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDADatabaseTool()._run('What drug is the most recently approved?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e5da3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"search\",\n",
    "        func=search.run,\n",
    "        description=\"General internet search for high level information \"\n",
    "    ),\n",
    "    ClinicalLinkTool(),\n",
    "    # FDADatabaseTool(),\n",
    "    WriteFileTool(root_dir=\"./data\"),\n",
    "    ReadFileTool(root_dir=\"./data\"),\n",
    "    process_csv,\n",
    "    query_website_tool,\n",
    "    HumanInputRun(), # Activate if you want the permit asking for help from the human\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f1a23896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Subbarao\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "    # human_in_the_loop=True, # Set to True if you want to add feedback at each step.\n",
    ")\n",
    "agent.chain.set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc71488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
